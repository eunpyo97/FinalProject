{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "전처리"
      ],
      "metadata": {
        "id": "48l4AyZjnLbL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PkPv__JDkh9i"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_path = \"\"\n",
        "val_datapath = \"\""
      ],
      "metadata": {
        "id": "BRVAgPoayt5V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "데이터 전처리(파이토치)"
      ],
      "metadata": {
        "id": "U2d8-NNtk7Ba"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_path = \"/content/drive/Othercomputers/내 PC/TEST_1/mask_train\"\n",
        "val_data_path = \"/content/drive/Othercomputers/내 PC/TEST_1/mask_val\"\n",
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "def data_process(train_data_path,val_data_path,batch_size):\n",
        "  train = transforms.Compose([\n",
        "      transforms.Resize((224,224)),#리사이징\n",
        "      transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5)),#정규화\n",
        "      transforms.RandomHorizontalFlip(),# 증강을위한 반전 적용\n",
        "      transforms.ToTensor()\n",
        "  ])\n",
        "  val = transforms.Compose([\n",
        "      transforms.Resize((224,224)),\n",
        "      transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5)),\n",
        "      transforms.ToTensor()\n",
        "  ])\n",
        "  #훈련셋 검증셋\n",
        "  train_data = datasets.ImageFolder(train_data_path,transform=train)\n",
        "  val_data = datasets.ImageFolder(val_data_path,transform=val)\n",
        "\n",
        "  #데이터로드 생성\n",
        "  train_loader = torch.utils.data.DataLoader(train_data,batch_size=batch_size,shuffle=True)\n",
        "  val_loader = torch.utils.data.DataLoader(val_data,batch_size=batch_size,shuffle=False)\n",
        "\n",
        "  return train_loader,val_loader"
      ],
      "metadata": {
        "id": "h78h_hMKtupR"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "데이터전처리(텐서플로우)"
      ],
      "metadata": {
        "id": "6QHNQi9rokrH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def data_process(train_data_path, val_data_path, batch_size):\n",
        "    # 훈련 데이터셋 생성: 디렉토리 구조에 따라 라벨 자동 생성\n",
        "    train_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "        train_data_path,\n",
        "        image_size=(224, 224),\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True\n",
        "    )\n",
        "\n",
        "    # 검증 데이터셋 생성\n",
        "    val_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "        val_data_path,\n",
        "        image_size=(224, 224),\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False\n",
        "    )\n",
        "\n",
        "    # 표준화\n",
        "    standardization_layer = tf.keras.layers.Normalization(axis=-1)\n",
        "\n",
        "\n",
        "    train_dataset = train_dataset.map(lambda x, y: (standardization_layer(x), y))\n",
        "    val_dataset = val_dataset.map(lambda x, y: (standardization_layer(x), y))\n",
        "\n",
        "    # 데이터 증강: 훈련 데이터에 대해 랜덤 좌우 반전 적용\n",
        "    augmentation_layer = tf.keras.layers.RandomFlip(\"horizontal\")\n",
        "    train_dataset = train_dataset.map(lambda x, y: (augmentation_layer(x, training=True), y))\n",
        "\n",
        "    return train_dataset, val_dataset\n"
      ],
      "metadata": {
        "id": "gYtoUR2nylS0"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 간단한 cnn 분류모델"
      ],
      "metadata": {
        "id": "v41ECDbMpefj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_path = \"/content/drive/Othercomputers/내 PC/TEST_1/mask_train\"\n",
        "val_data_path = \"/content/drive/Othercomputers/내 PC/TEST_1/mask_val\""
      ],
      "metadata": {
        "id": "p5fDP286pb4p"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# 데이터 전처리 함수: 이미지 로드, 표준화, 데이터 증강 적용\n",
        "def data_process(train_data_path, val_data_path, batch_size):\n",
        "    # 원본 훈련 데이터셋 생성 (클래스 이름 추출을 위해 별도로 생성)\n",
        "    train_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "        train_data_path,\n",
        "        image_size=(224, 224),\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True\n",
        "    )\n",
        "    # 원본 검증 데이터셋 생성\n",
        "    val_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "        val_data_path,\n",
        "        image_size=(224, 224),\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False\n",
        "    )\n",
        "\n",
        "    # 클래스 이름 저장\n",
        "    class_names = train_dataset.class_names\n",
        "\n",
        "    # 표준화 레이어: 평균 0, 표준편차 1로 변환\n",
        "    standardization_layer = tf.keras.layers.Normalization(axis=-1)\n",
        "    # 표준화 레이어를 훈련 이미지 데이터에 맞춰 학습\n",
        "    train_images = train_dataset.map(lambda x, y: x)\n",
        "    standardization_layer.adapt(train_images)\n",
        "\n",
        "    # 훈련 및 검증 데이터에 표준화 적용\n",
        "    train_dataset = train_dataset.map(lambda x, y: (standardization_layer(x), y))\n",
        "    val_dataset = val_dataset.map(lambda x, y: (standardization_layer(x), y))\n",
        "\n",
        "    # 데이터 증강: 훈련 데이터에 랜덤 좌우 반전 적용\n",
        "    augmentation_layer = tf.keras.layers.RandomFlip(\"horizontal\")\n",
        "    train_dataset = train_dataset.map(lambda x, y: (augmentation_layer(x, training=True), y))\n",
        "\n",
        "    return train_dataset, val_dataset, class_names\n"
      ],
      "metadata": {
        "id": "igvE8y1st4k1"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 데이터 경로 및 하이퍼파라미터 설정\n",
        "train_data_path = \"/content/drive/Othercomputers/내 PC/TEST_1/mask_train\"\n",
        "val_data_path = \"/content/drive/Othercomputers/내 PC/TEST_1/mask_val\"\n",
        "batch_size = 32\n",
        "\n",
        "# 전처리된 데이터셋과 클래스 정보를 불러옴\n",
        "train_dataset, val_dataset, class_names = data_process(train_data_path, val_data_path, batch_size)\n",
        "num_classes = len(class_names)\n",
        "print(\"클래스 이름:\", class_names)\n",
        "\n",
        "# 분류 모델 구성\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Input(shape=(224, 224, 3)),\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "# 모델 컴파일: 분류 문제이므로 손실함수로 sparse categorical crossentropy 사용\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# 모델 학습\n",
        "epochs = 15\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    validation_data=val_dataset,\n",
        "    epochs=epochs\n",
        ")\n",
        "\n",
        "# 모델 저장\n",
        "model_save_path = \"/content/drive/MyDrive/CNN_classification_model_PROTO.h5\"\n",
        "model.save(model_save_path)\n",
        "print(\"모델이 저장되었습니다:\", model_save_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A6M6l5W_pivd",
        "outputId": "26652d9e-14f5-40cd-9d54-ab5376d3e274"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 5994 files belonging to 4 classes.\n",
            "Found 1200 files belonging to 4 classes.\n",
            "클래스 이름: ['mask_labeled_angry', 'mask_labeled_happy', 'mask_labeled_panic', 'mask_labeled_sadness']\n",
            "Epoch 1/15\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 534ms/step - accuracy: 0.2534 - loss: 3.1104 - val_accuracy: 0.2542 - val_loss: 1.3864\n",
            "Epoch 2/15\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 179ms/step - accuracy: 0.2417 - loss: 1.3865 - val_accuracy: 0.2583 - val_loss: 1.3862\n",
            "Epoch 3/15\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 175ms/step - accuracy: 0.2669 - loss: 1.3853 - val_accuracy: 0.2517 - val_loss: 1.3871\n",
            "Epoch 4/15\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 175ms/step - accuracy: 0.2879 - loss: 1.3807 - val_accuracy: 0.2525 - val_loss: 1.3930\n",
            "Epoch 5/15\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 174ms/step - accuracy: 0.3227 - loss: 1.3696 - val_accuracy: 0.2842 - val_loss: 1.3985\n",
            "Epoch 6/15\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 175ms/step - accuracy: 0.3707 - loss: 1.3213 - val_accuracy: 0.2733 - val_loss: 1.4296\n",
            "Epoch 7/15\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 175ms/step - accuracy: 0.4422 - loss: 1.2524 - val_accuracy: 0.2717 - val_loss: 1.4793\n",
            "Epoch 8/15\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 175ms/step - accuracy: 0.5131 - loss: 1.1339 - val_accuracy: 0.2717 - val_loss: 1.5497\n",
            "Epoch 9/15\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 174ms/step - accuracy: 0.5752 - loss: 1.0135 - val_accuracy: 0.2550 - val_loss: 1.6742\n",
            "Epoch 10/15\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 174ms/step - accuracy: 0.6579 - loss: 0.8699 - val_accuracy: 0.2750 - val_loss: 1.7824\n",
            "Epoch 11/15\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 178ms/step - accuracy: 0.7088 - loss: 0.7557 - val_accuracy: 0.2675 - val_loss: 1.8753\n",
            "Epoch 12/15\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 175ms/step - accuracy: 0.7630 - loss: 0.6259 - val_accuracy: 0.2742 - val_loss: 1.8845\n",
            "Epoch 13/15\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 175ms/step - accuracy: 0.8077 - loss: 0.5340 - val_accuracy: 0.2933 - val_loss: 2.1762\n",
            "Epoch 14/15\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 176ms/step - accuracy: 0.8280 - loss: 0.4698 - val_accuracy: 0.2758 - val_loss: 2.1571\n",
            "Epoch 15/15\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 175ms/step - accuracy: 0.8608 - loss: 0.3834 - val_accuracy: 0.2792 - val_loss: 2.4258\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "모델이 저장되었습니다: /content/drive/MyDrive/CNN_classification_model_PROTO.h5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 데이터 테스트\n"
      ],
      "metadata": {
        "id": "29UmFHnB_Fzi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# 테스트 데이터 경로\n",
        "test_data_path = \"/content/drive/Othercomputers/내 PC/TEST_1/test/image-20250212T014410Z-001/image\"\n",
        "\n",
        "# 테스트 데이터 불러오기\n",
        "test_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    test_data_path,\n",
        "    image_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    shuffle=False  # 테스트셋은 순서를 유지하는 것이 좋음\n",
        ")\n",
        "\n",
        "# 표준화 함수\n",
        "def preprocess(image, label):\n",
        "    # 표준화: 평균과 표준편차를 사용하여 이미지 정규화\n",
        "    # 평균과 표준편차 계산\n",
        "    image = tf.cast(image, tf.float32)\n",
        "    mean = tf.reduce_mean(image)\n",
        "    stddev = tf.math.reduce_std(image)\n",
        "\n",
        "    image = (image - mean) / stddev  # 표준화\n",
        "    return image, label\n",
        "\n",
        "\n",
        "# 전처리 적용\n",
        "test_dataset = test_dataset.map(preprocess)\n",
        "\n",
        "# 모델 평가\n",
        "test_loss, test_acc = model.evaluate(test_dataset)\n",
        "print(f\"테스트 정확도: {test_acc * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IaXJPs6iqaK-",
        "outputId": "49abe604-1c50-47eb-bea3-9fe5f76156ee"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1200 files belonging to 4 classes.\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 2s/step - accuracy: 0.2632 - loss: 2.9634\n",
            "테스트 정확도: 27.42%\n"
          ]
        }
      ]
    }
  ]
}