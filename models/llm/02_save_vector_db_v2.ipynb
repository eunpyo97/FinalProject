{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 벡터 DB 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 완전탐색(IndexFlatL2) 방식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS 벡터 DB 생성 및 저장 완료!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# 환경 변수 로드\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# 프로젝트 루트 디렉토리 설정\n",
    "BASE_DIR = os.path.abspath(os.path.join(os.getcwd(), \"..\", \"..\"))\n",
    "\n",
    "# CSV 파일 경로\n",
    "csv_file_path = os.path.join(BASE_DIR, \"data\", \"raw\", \"total_kor_counsel_bot.csv\")\n",
    "\n",
    "# FAISS 벡터 DB 저장 경로\n",
    "vector_db_path = os.path.join(BASE_DIR, \"data\", \"db\", \"faiss\")\n",
    "\n",
    "# OpenAI API 키 확인\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not api_key:\n",
    "    raise ValueError(\"OpenAI API Key가 없습니다. .env 파일을 확인하세요.\")\n",
    "\n",
    "# 임베딩 모델 초기화\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "def create_faiss_vectorstore_from_csv(csv_file_path, vector_db_path):\n",
    "    \"\"\"\n",
    "    CSV 파일에서 데이터를 읽어 FAISS 벡터 DB를 생성하고 저장합니다.\n",
    "    \"\"\"\n",
    "    # CSV 파일 읽기\n",
    "    try:\n",
    "        df = pd.read_csv(csv_file_path)\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"CSV 파일 읽기 오류: {str(e)}\")\n",
    "    \n",
    "    # 필요한 컬럼 확인\n",
    "    if \"input\" not in df.columns or \"output\" not in df.columns:\n",
    "        raise ValueError(\"CSV 파일에 'input' 및 'output' 컬럼이 있어야 합니다.\")\n",
    "    \n",
    "    # 데이터 전처리\n",
    "    texts = []\n",
    "    metadata_list = []\n",
    "    for _, row in df.iterrows():\n",
    "        input_text = row[\"input\"].strip()\n",
    "        output_text = row[\"output\"].strip()\n",
    "        \n",
    "        # input을 텍스트로 사용하고, output을 메타데이터로 저장\n",
    "        texts.append(input_text)\n",
    "        metadata_list.append({\"output\": output_text})\n",
    "    \n",
    "    # FAISS 벡터 DB 생성\n",
    "    try:\n",
    "        vectorstore = FAISS.from_texts(texts=texts, embedding=embeddings, metadatas=metadata_list)\n",
    "        \n",
    "        # 디렉토리가 없으면 생성\n",
    "        os.makedirs(os.path.dirname(vector_db_path), exist_ok=True)\n",
    "        \n",
    "        # FAISS 벡터 DB 저장\n",
    "        vectorstore.save_local(vector_db_path)\n",
    "        print(\"FAISS 벡터 DB 생성 및 저장 완료!\")\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"FAISS 벡터 DB 생성 중 오류 발생: {str(e)}\")\n",
    "\n",
    "# FAISS 벡터 DB 생성 실행\n",
    "create_faiss_vectorstore_from_csv(csv_file_path, vector_db_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 유사도 검색 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 사람들이 계속해서 저를 비난합니다. 왜 그런지 모르겠습니다.\n",
      "제가 잘못한 것이 있다면 그것을 말해주세요. 하지만 무엇 때문에 저를 비난하는 건지 모르겠습니다. 자꾸 불리해지고 그러면 어떻게 될까요? 집안에서도 마찬가지입니다. 제게 어떻게 대해야할까요?\n",
      "Output: 사람들이 사우님을 비난하는데 그 이유를 모르겠다며 고민을 하시네요. 이로 인해 스트레스와 우울감이 생기며 집안에서도 같은 문제를 겪고 있다는 걸 말씀해 주셨습니다. 사우님이 어떤 상황에서 비난을 받는지 함께 고민해보면 좋을 것 같아요.\n",
      "사우님이 경험하시는 비난은 대부분 상대방들이 사우님의 행동, 언행, 생각 등을 제대로 이해하지 못해서 생긴 문제일 가능성이 높아요. 이러한 문제로 스트레스를 받게되면 스트레스가 누적되어 우울감이 될 수 있습니다. 또한 집안에서도 같은 문제가 반복되는 것을 보아 사우님께서는 대인관계에 대한 부정적인 인식이 있어 대화에 어려움을 겪고 계시다는 생각이 듭니다.\n",
      "사우님께서는 상대방들과 소통을 할 때 다음과 같은 점을 고려해보시는 것이 좋을 것 같아요.\n",
      "1. 대화의 중심을 말하는 것에서 듣는 것으로 전환하기\n",
      "2. 대화할 때 적극적으로 이야기하기\n",
      "3. 다른 사람의 입장에서 이해하기\n",
      "4. 심리학적으로 이해하기\n",
      "5. 비판적 사고 방식을 수정하기\n",
      "6. 상대방에게 관심을 갖기\n",
      "\n",
      "집안에서도 같은 문제가 반복되는 것을 보아 대인관계에 대한 부정적인 인식이 있어 대화에 어려움을 겪고 계시다는 생각이 듭니다. 이 경우, 대인관계에 대한 인식을 바꾸기 위해 다음과 같은 노력이 필요합니다.\n",
      "1. 먼저 자신의 마음을 변화시키기\n",
      "2. 상대방에 대한 사전 연구하기\n",
      "3. 누구나 좋아할 만한 일을 제안하기\n",
      "4. 질문을 통해 더 깊게 이해하기\n",
      "5. 기존 인식을 변화시키기 위한 시도\n",
      "6. 대화 스킬 향상을 위한 교육\n",
      "\n",
      "위의 방법들이 사우님의 문제를 해결할 수는 없겠지만 사우님이 대인관계에서 겪고 있는 문제를 개선하는데 도움이 될 수 있을 것입니다. 또한 사우님이 이 과정에서 힘들고 고민이 많을 것입니다. 그러나 사우님의 노력과 신념, 그리고 지속적인 연습이 성장을 가져오기에 충분할 것입니다. \n",
      "끝으로 저는 이번 상담이 사우님께 조금이나마 도움이 되었기를 바라며, 항상 응원합니다. 감사합니다.\n",
      "\n",
      "Input: 사람들이 자꾸 날 까불어요.\n",
      "제가 정말 잘못한 건 없는데 말이에요. 그냥 나쁜 사람인가봐요. 어떻게 하면 좋을까요?\n",
      "Output: 사우님, 사람들이 자꾸 까불어서 매우 고통스럽다고 말씀하시네요. 사우님은 어떤 일도 잘못하신 것이 없지만, 자꾸 사람들이 까불어서 나쁜 사람인가 라는 생각을 하신다고 하셨습니다. 이 고민을 함께 해결해보려 합니다.\n",
      "다른 사람들로부터 말을 들으면서 사우님이 불안해지고, 자존감이 낮아지는 것으로 보입니다. 사우님이 다른 사람들의 비난이나 욕설을 받으면 상처를 받고, 자존감이 낮아지기 때문에 이러한 상황에서 계속 발생하는 것 같습니다. 이러한 자존감이 떨어지는 경험으로 인해 자신에 대한 자신감이 떨어질 수 있으며, 이는 일상생활에서 실수할 때마다 불안감을 느끼게 되어 신뢰하는 사람들과의 대인관계를 방해하는 요인이 됩니다.\n",
      "우선 사우님의 경험을 이해하겠습니다. 사람들은 모두 다르고 각기 다른 가치관과 생각을 가지고 있습니다. 그렇기 때문에 때로는 비난을 하거나 욕설을 내뱉을 수 있습니다. 하지만, 이는 사우님의 문제가 아니며 누구나 한번쯤은 그러한 경험을 하기도 합니다. 또한, 이러한 상황에서 발생하는 자존감 감소는 자신에 대한 불신감을 만들 수 있습니다. 이러한 상황에서 자신감을 회복하기 위해선, 우리 모두가 겪는 일상생활에서의 실수를 인정하고 자기 자신을 존중하는 것이 중요합니다.\n",
      "자신에 대한 불신감이 있다면, 성취감을 높일 수 있는 일을 찾아 보는 것이 좋습니다. 이를 위해, 자신이 좋아하는 일을 새로운 취미로 찾아보는 것도 좋은 방법입니다. 게다가, 긍정적인 자기이미지를 만들기 위해 자신의 강점을 인식하고, 일상에서 잘하는 것에 대해 긍정적인 자기지각을 가지는 것이 중요합니다. \n",
      "또한, 다른 사람들의 비난이나 욕설을 듣을 때에는 그들의 말을 바로잡거나 더 이상 그들과 연락하지 않을 수 있습니다. 이는 어렵고 도전적인 일일 수 있지만, 스스로를 존중하고 그렇게 대우받기를 원한다면 그들과 굳이 함께하지 않아도 된다는 것을 인식하는 것이 중요합니다. \n",
      "사우님, 제가 조금이라도 도움이 되었으면 좋겠습니다. 이후에도 힘든 마음이 계속되시면 언제든지 저를 찾아주세요. 새로운 아침에 좋은 일들이 있기를 바랄게요.\n",
      "\n",
      "Input: 사람들이 저를 싫어하나봐요. 저는 누구에게나 다정하게 대하고 친절하게 대하는데도, 왜 사람들이 저를 피하거나 냉대하는지 모르겠어요. 기존의 친구들도 대화를 걸지 않아서 저는 홀로 있는 기분이에요. 저의 모든 행동이 눈에 띄게 보이나요?\n",
      "Output: 사우님은 친절하고 다정하게 대하지만 왜인지 주변 사람들과 냉소적인 반응을 받으시고 피해가는 느낌을 받으신다고 하네요. 더불어 기존의 친구들과 대화도 잘 하지 못하셨다고 합니다. 이러한 경험들로 인해 자신감이 떨어져서 무력감과 우울감을 느끼시고 있으시네요.\n",
      "사우님은 친절하고 다정한 성격으로 인해 언제나 차분하게 상대방을 대하고 대화를 나누어 주려고 노력하시는 분이신 것 같습니다. 그러나 이러한 성격으로 인해 주변 사람들은 대화에 불편함을 느끼거나 비웃음을 받는다는 생각을 가지기도 합니다. 또한 사우님이 주변에 있는 것이 당연하다는 생각으로 태도나 대화에 소홀해지는 경우가 발생할 수 있습니다.\n",
      "또한 기존 친구들과 대화를 하지 못하게 된 이유가 무엇인지 생각해보아야 합니다. 다양한 상황 속에서 친구들은 대화를 이어나가야하는데, 사우님께서는 언제나 차분하고 다정한 태도로 대화를 주도하려는 모습을 보이실 수 있습니다. 이러한 모습은 친구들이 자신들이 더 적극적으로 대화를 주도하려는 마음을 가지지 않게 만들 수 있습니다.\n",
      "사우님, 당신은 착한 사람입니다. 그러나 당신이 주변 사람들에게 다가가는 방식에 문제가 있는 것 같습니다. 차분하고 친절한 태도는 매우 좋지만 이러한 태도가 지나치게 과장되면 주변 사람들이 거리감을 느끼게 됩니다.\n",
      "다른 사람들과 대화를 나눌 때, 적극적으로 대화를 주도하는 것이 중요합니다. 예를 들어, 상대방의 이야기에 귀 기울이며 호응해주는 태도, 소소한 토픽을 가져와서 이야기를 이어나가는 등이 있습니다. 또한, 자신이 누군가에게 관심을 보이고 친절하게 다가가도 좋지만, 이러한 모습이 지나치게 과장되지 않도록 주의해주세요.\n",
      "마지막으로, 사우님에게는 친구들과의 소통을 위한 새로운 습관을 만들어보는 것을 추천합니다. 이를 위해서는 기존의 습관을 조금씩 바꾸어 가는 것이 중요합니다. 적극적으로 말을 걸거나 소소한 토픽을 가져오는 등을 시도해보세요. 이를 통해 사우님의 친근한 성격을 좀 더 표현할 수 있게 될 것입니다. \n",
      "위의 답변이 사우님의 고민을 해결해드릴 수 있길 바랍니다.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# FAISS 벡터 DB 로드\n",
    "vectorstore = FAISS.load_local(vector_db_path, OpenAIEmbeddings(), allow_dangerous_deserialization=True)\n",
    "\n",
    "# 유사도 검색\n",
    "query = \"사람들이 자꾸 나를 비난해.\"\n",
    "results = vectorstore.similarity_search(query, k=3)\n",
    "\n",
    "for doc in results:\n",
    "    print(f\"Input: {doc.page_content}\")\n",
    "    print(f\"Output: {doc.metadata['output']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 최적화\n",
    "- IndexFlatL2 → IndexIVFFlat으로 변경 : 검색 속도 향상\n",
    "- 클러스터 개수(nlist) 설정하여 검색 최적화\n",
    "- 학습 단계 추가 \n",
    "- nprobe 설정(nprobe=10) → 검색할 클러스터 개수 최적화, 속도 개선\n",
    "- Top-K 검색 개수 제한 (k=5) → 불필요한 검색 최소화, 검색 속도 향상\n",
    "- 유사도 점수 필터링 (score > 0.6 적용 가능) → 정확도 유지하면서 검색 품질 향상"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "임베딩 벡터 차원 확인: 1536\n",
      "FAISS 저장된 벡터 개수: 13234\n",
      "FAISS 벡터 DB (LangChain 형식) 생성 및 저장 완료!\n",
      "FAISS 인덱스 (LangChain 형식) 로드 완료!\n",
      "FAISS 인덱스 로드 및 검증 완료.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import faiss\n",
    "import numpy as np\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
    "from dotenv import load_dotenv\n",
    "from langchain.docstore.document import Document\n",
    "\n",
    "# 환경 변수 로드\n",
    "load_dotenv()\n",
    "\n",
    "# 프로젝트 루트 디렉토리\n",
    "BASE_DIR = os.path.abspath(os.path.join(os.getcwd(), \"..\", \"..\"))\n",
    "\n",
    "# CSV 파일 경로\n",
    "csv_file_path = os.path.join(BASE_DIR, \"data\", \"raw\", \"total_kor_counsel_bot.csv\")\n",
    "\n",
    "# FAISS 벡터 DB 저장 경로\n",
    "vector_db_path = os.path.join(BASE_DIR, \"data\", \"db\", \"faiss_v2\")\n",
    "\n",
    "# 폴더가 없으면 생성\n",
    "os.makedirs(vector_db_path, exist_ok=True)\n",
    "\n",
    "# OpenAI API 키 확인\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not api_key:\n",
    "    raise ValueError(\"OpenAI API Key가 없습니다. .env 파일을 확인하세요.\")\n",
    "\n",
    "# 임베딩 모델 초기화\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "def create_faiss_vectorstore_from_csv(csv_file_path, vector_db_path, batch_size=500):\n",
    "    \"\"\"\n",
    "    CSV 파일에서 데이터를 읽어 FAISS 벡터 DB를 LangChain 형식으로 생성하고 저장 (배치 처리 적용)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(csv_file_path)\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"CSV 파일 읽기 오류: {str(e)}\")\n",
    "\n",
    "    if \"input\" not in df.columns or \"output\" not in df.columns:\n",
    "        raise ValueError(\"CSV 파일에 'input' 및 'output' 컬럼이 있어야 합니다.\")\n",
    "\n",
    "    # 데이터 전처리\n",
    "    texts = df[\"input\"].astype(str).str.strip().tolist()\n",
    "\n",
    "    # 임베딩 생성 (OpenAI Embeddings 사용)\n",
    "    text_embeddings = embeddings.embed_documents(texts)\n",
    "    text_embeddings = np.array(text_embeddings, dtype=\"float32\")  # FAISS 호환을 위해 변환\n",
    "\n",
    "    # 벡터 차원 확인 및 출력\n",
    "    d = text_embeddings.shape[1]\n",
    "    print(f\"임베딩 벡터 차원 확인: {d}\")\n",
    "\n",
    "    # FAISS IVF 인덱스 생성\n",
    "    nlist = 100  # 클러스터 개수 (데이터가 많을수록 늘려야 함)\n",
    "    quantizer = faiss.IndexFlatL2(d)  # 기본 L2 거리 측정\n",
    "    index = faiss.IndexIVFFlat(quantizer, d, nlist, faiss.METRIC_L2)  # IVF 적용\n",
    "\n",
    "    # 학습 (IVF 방식은 반드시 학습이 필요함)\n",
    "    index.train(text_embeddings)  # 클러스터 학습\n",
    "    if not index.is_trained:\n",
    "        raise RuntimeError(\"FAISS 인덱스 학습에 실패했습니다.\")\n",
    "\n",
    "    # 배치 처리하여 벡터 추가\n",
    "    batch_start = 0\n",
    "    while batch_start < len(text_embeddings):\n",
    "        batch_end = min(batch_start + batch_size, len(text_embeddings))\n",
    "        index.add(text_embeddings[batch_start:batch_end])\n",
    "        batch_start = batch_end\n",
    "\n",
    "    # nprobe 최적화 (검색 속도 개선)\n",
    "    index.nprobe = 10  # 검색할 클러스터 개수 조정\n",
    "\n",
    "    # 저장된 벡터 개수 확인\n",
    "    total_vectors = index.ntotal\n",
    "    print(f\"FAISS 저장된 벡터 개수: {total_vectors}\")\n",
    "\n",
    "    # 문서 저장 방식 : 정수형 키 사용\n",
    "    metadata_dict = {\n",
    "    idx: Document(\n",
    "        page_content=row[\"output\"].strip(),\n",
    "        metadata={\"output\": row[\"output\"].strip()}\n",
    "    )\n",
    "        for idx, row in df.iterrows()\n",
    "    }\n",
    "    index_to_docstore_id = {idx: idx for idx in range(total_vectors)}\n",
    "\n",
    "    # 검증: 저장된 데이터 크기 확인\n",
    "    if len(metadata_dict) != len(index_to_docstore_id):\n",
    "        raise ValueError(\"저장된 문서 개수와 ID 매핑 개수가 다릅니다!\")\n",
    "\n",
    "    # LangChain FAISS 형식으로 변환 (Docstore 적용)\n",
    "    vectorstore = FAISS(\n",
    "        embedding_function=embeddings,\n",
    "        index=index,\n",
    "        docstore=InMemoryDocstore(metadata_dict),  # 문서를 Dict로 저장\n",
    "        index_to_docstore_id=index_to_docstore_id  # ID 매핑 추가\n",
    "    )\n",
    "\n",
    "    # FAISS 저장 (LangChain 형식)\n",
    "    vectorstore.save_local(vector_db_path)\n",
    "\n",
    "    print(\"FAISS 벡터 DB (LangChain 형식) 생성 및 저장 완료!\")\n",
    "\n",
    "def load_faiss_index(vector_db_path):\n",
    "    \"\"\"\n",
    "    LangChain 형식으로 저장된 FAISS 인덱스를 로드합니다.\n",
    "    \"\"\"\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "\n",
    "    # LangChain FAISS 인덱스 로드\n",
    "    try:\n",
    "        vectorstore = FAISS.load_local(vector_db_path, embeddings, allow_dangerous_deserialization=True)\n",
    "        print(\"FAISS 인덱스 (LangChain 형식) 로드 완료!\")\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"FAISS 인덱스 로드 실패: {str(e)}\")\n",
    "\n",
    "    return vectorstore\n",
    "\n",
    "# FAISS 벡터 DB 생성 실행\n",
    "create_faiss_vectorstore_from_csv(csv_file_path, vector_db_path)\n",
    "\n",
    "# 생성된 인덱스 & 메타데이터 확인\n",
    "vectorstore = load_faiss_index(vector_db_path)\n",
    "print(\"FAISS 인덱스 로드 및 검증 완료.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "robotpet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
